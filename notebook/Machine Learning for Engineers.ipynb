{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Engineers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Some Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_row(cols, max_length=20):\n",
    "    col_width = max_length\n",
    "    print(\"\".join(str(word).ljust(col_width) for word in cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(pickle_file):\n",
    "    import pickle\n",
    "\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print('Unable to load data from', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "data = load_data('partial_notMNIST.pickle')\n",
    "train_dataset = data['train_dataset']\n",
    "train_labels = data['train_labels']\n",
    "test_dataset = data['test_dataset']\n",
    "test_labels = data['test_labels']\n",
    "valid_dataset = data['valid_dataset']\n",
    "valid_labels = data['valid_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADJCAYAAAAzQMlMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51140969b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def one_hot_to_char(one_hot):\n",
    "    return \"ABCDEFGHIJKLMOPQRSTUVWXYZ\"[one_hot]\n",
    "\n",
    "n = 16\n",
    "rows = 2\n",
    "for i in range(1,1+n):\n",
    "    image_to_show = random.randint(0,len(train_dataset))\n",
    "    \n",
    "    plt.subplot(rows,n/rows,i)\n",
    "    plt.imshow(train_dataset[image_to_show], cmap=\"gray\")\n",
    "    plt.title(one_hot_to_char(train_labels[image_to_show]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (10000, 28, 28)\n",
      "Test:  (1000, 28, 28)\n",
      "Valid:  (2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", train_dataset.shape)\n",
    "print(\"Test: \", test_dataset.shape)\n",
    "print(\"Valid: \", valid_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 0: Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (np.sum(np.array(predictions) == np.array(labels))\n",
    "          / len(predictions))\n",
    "\n",
    "def evaluate_classifier(classifier):  \n",
    "    # Train\n",
    "    classifier.fit(train_dataset, train_labels)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = classifier.predict(test_dataset)\n",
    "\n",
    "    print(\"Test accuracy: %s\" % accuracy(predictions, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomClassifier:\n",
    "    import random\n",
    "    \n",
    "    def fit(self, test_data, test_labels):\n",
    "        self.seen_labels = set(test_labels)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return [random.sample(self.seen_labels,1)[0] for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.108\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(RandomClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Tensor Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    A = tf.constant(np.array([1,2,3,4,5]))\n",
    "    B = tf.constant(np.array([1,2,3,4,5]))\n",
    "    R = A + B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 2,  4,  6,  8, 10])]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    res = session.run([R])\n",
    "    print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: Logistic Regression using TensorFlow\n",
    "\n",
    "Let's implement the logistic regression using tensor flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def to_one_hot(labels):\n",
    "    return (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "\n",
    "def from_one_hot(labels):\n",
    "    return np.argmax(labels,1)\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = to_one_hot(labels)\n",
    "  return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TensorLogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.num_steps = 1000\n",
    "    \n",
    "    def softmax_output(self, weights, biases, data):\n",
    "        logits = tf.matmul(data, weights) + biases\n",
    "        # Predict!\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "        return prediction, logits\n",
    "    \n",
    "    def fit(self, train_dataset, train_labels):\n",
    "        train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "        \n",
    "        with graph.as_default():\n",
    "          # Load the Data\n",
    "          tf_train_dataset = tf.constant(train_dataset)\n",
    "          tf_train_labels = tf.constant(train_labels)\n",
    "          tf_valid_dataset = tf.constant(valid_dataset)\n",
    "          tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "          # Linear Model\n",
    "          weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "          biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "          prediction, logits = self.softmax_output(weights, biases, tf_train_dataset)  \n",
    "            \n",
    "          loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "\n",
    "          # Optimizer.\n",
    "          optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "          \n",
    "        \n",
    "        with tf.Session(graph=graph) as session:\n",
    "          print_row(['Step', 'Loss', 'A-Train'])\n",
    "          tf.global_variables_initializer().run()\n",
    "          for step in range(self.num_steps):\n",
    "            w, b, _, l, predictions = session.run([weights, biases, optimizer, loss, prediction])\n",
    "            if (step % 100 == 0):\n",
    "              train_acc = accuracy(from_one_hot(predictions), from_one_hot(train_labels))                  \n",
    "\n",
    "              print_row([step, l, train_acc])\n",
    "                \n",
    "          self.weights = w\n",
    "          self.biases = b\n",
    "            \n",
    "    def predict(self, data):\n",
    "        data,_ = reformat(data, np.arange(10))\n",
    "        \n",
    "        with graph.as_default():\n",
    "            weights = tf.constant(self.weights)\n",
    "            biases = tf.constant(self.biases)\n",
    "            tfdata = tf.constant(data)\n",
    "            prediction, logits = self.softmax_output(weights, biases, tfdata)\n",
    "            \n",
    "        with tf.Session(graph=graph) as session:\n",
    "            tf.global_variables_initializer().run()\n",
    "            predictions, logits = session.run([prediction, logits])\n",
    "            return from_one_hot(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                A-Train             \n",
      "0                   14.499              0.1323              \n",
      "100                 2.30174             0.7179              \n",
      "200                 1.85821             0.7506              \n",
      "300                 1.61308             0.7635              \n",
      "400                 1.44739             0.7738              \n",
      "500                 1.32386             0.7832              \n",
      "600                 1.22653             0.7869              \n",
      "700                 1.14732             0.7909              \n",
      "800                 1.08143             0.7957              \n",
      "900                 1.02559             0.7995              \n",
      "Test accuracy: 0.817\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(TensorLogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "\n",
    "train_subset = 128\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # Load the Data\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Linear Model\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predict!\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           Acc-Valid           \n",
      "0                   16.6153             0.109375            0.1155              \n",
      "500                 0.428728            0.875               0.7455              \n",
      "1000                1.53497             0.6796875           0.757               \n",
      "1500                1.27728             0.7578125           0.76                \n",
      "2000                0.929354            0.765625            0.7655              \n",
      "2500                0.868899            0.796875            0.759               \n",
      "Test accuracy: 0.8280%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3000\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print_row(['Step', 'Loss', 'Acc-Train', 'Acc-Valid'])\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    \n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 500 == 0):\n",
    "      train_acc = accuracy(predictions, batch_labels)\n",
    "      valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "        \n",
    "      print_row([step, l, train_acc, valid_acc])\n",
    "  print(\"Test accuracy: %.4f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: First Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_relu = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_relu]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_relu]))\n",
    "  \n",
    "  hidden_input = tf.matmul(tf_train_dataset, weights_1) + biases_1\n",
    "  hidden_output = tf.nn.relu(hidden_input)\n",
    "\n",
    "  weights_2 = tf.Variable(tf.truncated_normal([num_relu, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  # Training computation.\n",
    "  logits = tf.matmul(hidden_output, weights_2) + biases_2\n",
    "\n",
    "  # Loss to optimize\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset,weights_1)+biases_1), weights_2) + biases_2)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset,weights_1)+biases_1), weights_2) + biases_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           Acc-Valid           \n",
      "0                   327.996             0.0859375           0.404               \n",
      "500                 0.305806            0.984375            0.8145              \n",
      "1000                0.021833            0.9921875           0.832               \n",
      "1500                5.48303e-05         1.0                 0.8285              \n",
      "2000                1.29803e-05         1.0                 0.8305              \n",
      "2500                0.0                 1.0                 0.829               \n",
      "3000                7.46887e-07         1.0                 0.8295              \n",
      "3500                2.42143e-08         1.0                 0.829               \n",
      "4000                9.87695e-06         1.0                 0.827               \n",
      "Test accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "num_steps = 4001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print_row(['Step', 'Loss', 'Acc-Train', 'Acc-Valid'])\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    \n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 500 == 0):\n",
    "      test_acc = accuracy(predictions, batch_labels)\n",
    "      valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "        \n",
    "      print_row([step, l, test_acc, valid_acc])\n",
    "  print(\"Test accuracy: %.4f\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 5: Regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_relu = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_relu]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_relu]))\n",
    "  \n",
    "  hidden_input = tf.matmul(tf_train_dataset, weights_1) + biases_1\n",
    "  hidden_output = tf.nn.relu(hidden_input)\n",
    "  regularized_output_1 = tf.nn.dropout(hidden_output, 0.5)\n",
    "\n",
    "  weights_2 = tf.Variable(tf.truncated_normal([num_relu, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  # Training computation.\n",
    "  logits = tf.matmul(regularized_output_1, weights_2) + biases_2\n",
    "\n",
    "  # Loss to optimize\n",
    "  beta = tf.constant(0.001)\n",
    "  l2_w1 = beta * tf.nn.l2_loss(weights_1)\n",
    "  l2_w2 = beta * tf.nn.l2_loss(weights_2)\n",
    "  logits = tf.matmul(hidden_output, weights_2) + biases_2 \n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels)) + l2_w1 + l2_w2\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset,weights_1)+biases_1), weights_2) + biases_2)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset,weights_1)+biases_1), weights_2) + biases_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           Acc-Valid           \n",
      "0                   610.83              0.140625            0.251               \n",
      "1000                114.785             1.0                 0.809               \n",
      "2000                42.226              1.0                 0.813               \n",
      "3000                15.5832             1.0                 0.8305              \n",
      "Test accuracy: 0.8980%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 4000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print_row(['Step', 'Loss', 'Acc-Train', 'Acc-Valid'])\n",
    "  for step in range(num_steps):\n",
    "    # Pick Minibatch\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    \n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "      test_acc = accuracy(predictions, batch_labels)\n",
    "      valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "        \n",
    "      print_row([step, l, test_acc, valid_acc])\n",
    "  print(\"Test accuracy: %.4f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Demo 6: Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (10000, 28, 28, 1) (10000, 10)\n",
      "Validation set (2000, 28, 28, 1) (2000, 10)\n",
      "Test set (1000, 28, 28, 1) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = load_data('partial_notMNIST.pickle')\n",
    "train_dataset = data['train_dataset']\n",
    "train_labels = data['train_labels']\n",
    "test_dataset = data['test_dataset']\n",
    "test_labels = data['test_labels']\n",
    "valid_dataset = data['valid_dataset']\n",
    "valid_labels = data['valid_labels']\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    \n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    \n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           Acc-Valid           \n",
      "0                   3.5968              0.0625              0.1605              \n",
      "1000                0.80587             0.625               0.828               \n",
      "2000                0.245534            0.9375              0.8465              \n",
      "3000                0.336098            0.9375              0.852               \n",
      "4000                0.319397            0.875               0.853               \n",
      "5000                0.701432            0.8125              0.852               \n",
      "6000                0.0823003           1.0                 0.8525              \n",
      "7000                0.0349664           1.0                 0.8535              \n",
      "8000                0.0623412           1.0                 0.85                \n",
      "9000                0.00409627          1.0                 0.8565              \n",
      "10000               0.0646515           0.9375              0.841               \n",
      "Test accuracy: 0.8990%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print_row(['Step', 'Loss', 'Acc-Train', 'Acc-Valid'])\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % (num_steps // 10) == 0):\n",
    "      test_acc = accuracy(predictions, batch_labels)\n",
    "      valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "      print_row([step, l, test_acc, valid_acc])   \n",
    "  print('Test accuracy: %.4f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

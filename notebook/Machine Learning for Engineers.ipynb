{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Engineers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Some Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_row(cols, max_length=20):\n",
    "    col_width = max_length\n",
    "    print(\"\".join(str(word).ljust(col_width) for word in cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(pickle_file):\n",
    "    import pickle\n",
    "\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print('Unable to load data from', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "data = load_data('partial_notMNIST.pickle')\n",
    "train_dataset = data['train_dataset']\n",
    "train_labels = data['train_labels']\n",
    "test_dataset = data['test_dataset']\n",
    "test_labels = data['test_labels']\n",
    "valid_dataset = data['valid_dataset']\n",
    "valid_labels = data['valid_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADJCAYAAAAzQMlMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d7856b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def label_to_char(one_hot):\n",
    "    return \"ABCDEFGHIJKLMOPQRSTUVWXYZ\"[one_hot]\n",
    "\n",
    "\n",
    "n = 16\n",
    "rows = 2\n",
    "for i in range(1,1+n):\n",
    "    image_to_show = random.randint(0,len(train_dataset))\n",
    "\n",
    "    plt.subplot(rows,n/rows,i)\n",
    "    plt.imshow(train_dataset[image_to_show], cmap=\"gray\")\n",
    "    plt.title(label_to_char(train_labels[image_to_show]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (10000, 28, 28)\n",
      "Test:  (1000, 28, 28)\n",
      "Valid:  (2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", train_dataset.shape)\n",
    "print(\"Test: \", test_dataset.shape)\n",
    "print(\"Valid: \", valid_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 0: Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (np.sum(np.array(predictions) == np.array(labels))\n",
    "          / len(predictions))\n",
    "\n",
    "def evaluate_classifier(classifier):  \n",
    "    # Train\n",
    "    classifier.fit(train_dataset, train_labels)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = classifier.predict(test_dataset)\n",
    "\n",
    "    print(\"Test accuracy: %s\" % accuracy(predictions, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomClassifier:\n",
    "    import random\n",
    "    \n",
    "    def fit(self, test_data, test_labels):\n",
    "        self.seen_labels = set(test_labels)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return [random.sample(self.seen_labels,1)[0] for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.109\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(RandomClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Tensor Flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    A = tf.constant(np.array([1,2,3,4,5]))\n",
    "    B = tf.constant(np.array([1,2,3,4,5]))\n",
    "    R = A + B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 2,  4,  6,  8, 10])]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    res = session.run([R])\n",
    "    print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: Logistic Regression using TensorFlow\n",
    "\n",
    "Let's implement the logistic regression using tensor flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "# Convert 2 to [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "def to_one_hot(labels):\n",
    "    return (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "\n",
    "def from_one_hot(labels):\n",
    "    return np.argmax(labels,1)\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  labels = to_one_hot(labels)\n",
    "  return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TensorLogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.num_steps = 1000\n",
    "       \n",
    "    def fit(self, train_dataset, train_labels):\n",
    "        train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "        \n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "          # Load the Data\n",
    "          tf_train_dataset = tf.constant(train_dataset)\n",
    "          tf_train_labels = tf.constant(train_labels)\n",
    "\n",
    "          # Linear Model\n",
    "          weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "          biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "          logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "          prediction = tf.nn.softmax(logits) \n",
    "            \n",
    "          loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "\n",
    "          # Optimizer.\n",
    "          optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "          \n",
    "        \n",
    "        with tf.Session(graph=graph) as session:\n",
    "          print_row(['Step', 'Loss', 'A-Train'])\n",
    "          tf.global_variables_initializer().run()\n",
    "          for step in range(self.num_steps):\n",
    "            w, b, _, l, predictions = session.run([weights, biases, optimizer, loss, prediction])\n",
    "            if (step % 100 == 0):\n",
    "              train_acc = accuracy(from_one_hot(predictions), from_one_hot(train_labels))                  \n",
    "\n",
    "              print_row([step, l, train_acc])\n",
    "                \n",
    "          self.weights = w\n",
    "          self.biases = b\n",
    "            \n",
    "    def predict(self, data):\n",
    "        data,_ = reformat(data, np.arange(10))\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            weights = tf.constant(self.weights)\n",
    "            biases = tf.constant(self.biases)\n",
    "            tfdata = tf.constant(data)\n",
    "            logits = tf.matmul(data, weights) + biases\n",
    "            \n",
    "            prediction = tf.nn.softmax(logits)\n",
    "            \n",
    "        with tf.Session(graph=graph) as session:\n",
    "            tf.global_variables_initializer().run()\n",
    "            predictions, _ = session.run([prediction, logits])\n",
    "            return from_one_hot(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                A-Train             \n",
      "0                   17.085              0.1207              \n",
      "100                 2.31932             0.722               \n",
      "200                 1.86872             0.7511              \n",
      "300                 1.62002             0.7647              \n",
      "400                 1.45259             0.772               \n",
      "500                 1.32918             0.7784              \n",
      "600                 1.23259             0.7848              \n",
      "700                 1.15374             0.7909              \n",
      "800                 1.0877              0.7968              \n",
      "900                 1.03148             0.8005              \n",
      "Test accuracy: 0.824\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(TensorLogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: First Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.num_steps = 5001\n",
    "        self.batch_size = 128\n",
    "        self.num_relu = 1024\n",
    "        self.image_size = 28\n",
    "    \n",
    "    def fit(self, train_data, train_labels):\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "          tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                            shape=(self.batch_size, self.image_size * self.image_size))\n",
    "          tf_train_labels = tf.placeholder(tf.float32, shape=(self.batch_size, num_labels))\n",
    "\n",
    "          # Variables.\n",
    "          weights_1 = tf.Variable(tf.truncated_normal([self.image_size * self.image_size, self.num_relu]))\n",
    "          biases_1 = tf.Variable(tf.zeros([self.num_relu]))\n",
    "\n",
    "          hidden_input = tf.matmul(tf_train_dataset, weights_1) + biases_1\n",
    "          hidden_output = tf.nn.relu(hidden_input)\n",
    "\n",
    "          weights_2 = tf.Variable(tf.truncated_normal([self.num_relu, num_labels]))\n",
    "          biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "          # Training computation.\n",
    "          logits = tf.matmul(hidden_output, weights_2) + biases_2\n",
    "\n",
    "          # Loss to optimize\n",
    "          loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "\n",
    "          # Optimizer.\n",
    "          optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "          # Predictions for the training, validation, and test data.\n",
    "          train_prediction = tf.nn.softmax(logits)\n",
    "        \n",
    "        dataset, labels = reformat(train_dataset, train_labels)\n",
    "\n",
    "        with tf.Session(graph=graph) as session:\n",
    "          tf.global_variables_initializer().run()\n",
    "          print_row(['Step', 'Loss', 'Acc-Train'])\n",
    "          for step in range(self.num_steps):\n",
    "            offset = (step * self.batch_size) % (labels.shape[0] - self.batch_size)\n",
    "            batch_data = dataset[offset:(offset + self.batch_size), :]\n",
    "            batch_labels = labels[offset:(offset + self.batch_size), :]\n",
    "\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "\n",
    "            _, l, predictions, w1, b1, w2, b2 = session.run(\n",
    "                [\n",
    "                    optimizer, loss, train_prediction, \n",
    "                    weights_1, biases_1, weights_2, biases_2\n",
    "                ], \n",
    "                feed_dict=feed_dict\n",
    "            )\n",
    "\n",
    "            if (step % 500 == 0):\n",
    "              test_acc = accuracy(from_one_hot(predictions), from_one_hot(batch_labels))\n",
    "\n",
    "              print_row([step, l, test_acc])\n",
    "        \n",
    "        self.weights_1 = w1\n",
    "        self.biases_1 = b1\n",
    "        self.weights_2 = w2\n",
    "        self.biases_2 = b2\n",
    "        \n",
    "    def predict(self, data):\n",
    "        data,_ = reformat(data, np.arange(10))\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            weights_1 = tf.constant(self.weights_1)\n",
    "            biases_1 = tf.constant(self.biases_1)\n",
    "            weights_2 = tf.constant(self.weights_2)\n",
    "            biases_2 = tf.constant(self.biases_2)\n",
    "            tfdata = tf.constant(data)\n",
    "            \n",
    "            hidden_input = tf.matmul(tfdata, weights_1) + biases_1\n",
    "            hidden_output = tf.nn.relu(hidden_input)\n",
    "            \n",
    "            logits = tf.matmul(hidden_output, weights_2) + biases_2\n",
    "            \n",
    "            prediction = tf.nn.softmax(logits)\n",
    "            \n",
    "        with tf.Session(graph=graph) as session:\n",
    "            tf.global_variables_initializer().run()\n",
    "            predictions, _ = session.run([prediction, logits])\n",
    "            return from_one_hot(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           \n",
      "0                   351.996             0.0859375           \n",
      "500                 13.1669             0.9296875           \n",
      "1000                1.46369             0.9609375           \n",
      "1500                0.0258517           0.9921875           \n",
      "2000                2.04867e-06         1.0                 \n",
      "2500                3.01042e-06         1.0                 \n",
      "3000                7.72994e-08         1.0                 \n",
      "3500                0.0                 1.0                 \n",
      "4000                2.6334e-06          1.0                 \n",
      "4500                7.72737e-05         1.0                 \n",
      "5000                1.3941e-06          1.0                 \n",
      "Test accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(TensorNeuralNetwork())\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "\n",
    "train_subset = 128\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # Load the Data\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Linear Model\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predict!\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           Acc-Valid           \n",
      "0                   15.2293             0.09375             0.181               \n",
      "500                 0.630547            0.859375            0.7515              \n",
      "1000                1.5281              0.7265625           0.7545              \n",
      "1500                1.18858             0.7578125           0.7535              \n",
      "2000                0.710201            0.8203125           0.7605              \n",
      "2500                0.919894            0.7421875           0.764               \n",
      "3000                0.508534            0.859375            0.764               \n",
      "3500                0.831948            0.8046875           0.7645              \n",
      "4000                0.601305            0.7890625           0.7635              \n",
      "4500                0.66123             0.84375             0.762               \n",
      "5000                0.533061            0.828125            0.7665              \n",
      "5500                0.406684            0.8671875           0.7775              \n",
      "6000                0.386919            0.890625            0.768               \n",
      "6500                0.345753            0.8984375           0.77                \n",
      "7000                0.427847            0.875               0.7725              \n",
      "7500                0.583234            0.8515625           0.778               \n",
      "8000                0.456624            0.8671875           0.7645              \n",
      "8500                0.333856            0.8984375           0.777               \n",
      "9000                0.275509            0.9296875           0.7625              \n",
      "9500                0.316204            0.90625             0.7645              \n",
      "Test accuracy: 0.8400%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print_row(['Step', 'Loss', 'Acc-Train', 'Acc-Valid'])\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    \n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 500 == 0):\n",
    "      train_acc = accuracy(predictions, batch_labels)\n",
    "      valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "        \n",
    "      print_row([step, l, train_acc, valid_acc])\n",
    "  print(\"Test accuracy: %.4f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 5: Regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_relu = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_relu]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_relu]))\n",
    "  \n",
    "  hidden_input = tf.matmul(tf_train_dataset, weights_1) + biases_1\n",
    "  hidden_output = tf.nn.relu(hidden_input)\n",
    "  regularized_output_1 = tf.nn.dropout(hidden_output, 0.5)\n",
    "\n",
    "  weights_2 = tf.Variable(tf.truncated_normal([num_relu, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  # Training computation.\n",
    "  logits = tf.matmul(regularized_output_1, weights_2) + biases_2\n",
    "\n",
    "  # Loss to optimize\n",
    "  beta = tf.constant(0.001)\n",
    "  l2_w1 = beta * tf.nn.l2_loss(weights_1)\n",
    "  l2_w2 = beta * tf.nn.l2_loss(weights_2)\n",
    "  logits = tf.matmul(hidden_output, weights_2) + biases_2 \n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels)) + l2_w1 + l2_w2\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset,weights_1)+biases_1), weights_2) + biases_2)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset,weights_1)+biases_1), weights_2) + biases_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           Acc-Valid           \n",
      "0                   621.177             0.09375             0.2445              \n",
      "1000                114.794             1.0                 0.819               \n",
      "2000                42.2234             1.0                 0.82                \n",
      "3000                15.5679             1.0                 0.833               \n",
      "Test accuracy: 0.8990%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 4000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print_row(['Step', 'Loss', 'Acc-Train', 'Acc-Valid'])\n",
    "  for step in range(num_steps):\n",
    "    # Pick Minibatch\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    \n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    \n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "      test_acc = accuracy(predictions, batch_labels)\n",
    "      valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "        \n",
    "      print_row([step, l, test_acc, valid_acc])\n",
    "  print(\"Test accuracy: %.4f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Demo 6: Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (10000, 28, 28, 1) (10000, 10)\n",
      "Validation set (2000, 28, 28, 1) (2000, 10)\n",
      "Test set (1000, 28, 28, 1) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = load_data('partial_notMNIST.pickle')\n",
    "train_dataset = data['train_dataset']\n",
    "train_labels = data['train_labels']\n",
    "test_dataset = data['test_dataset']\n",
    "test_labels = data['test_labels']\n",
    "valid_dataset = data['valid_dataset']\n",
    "valid_labels = data['valid_labels']\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    \n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    \n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step                Loss                Acc-Train           Acc-Valid           \n",
      "0                   4.37245             0.0                 0.102               \n",
      "1000                0.990903            0.8125              0.8335              \n",
      "2000                0.148068            0.9375              0.8495              \n",
      "3000                0.380244            0.875               0.8515              \n",
      "4000                0.351485            0.9375              0.8535              \n",
      "5000                0.290573            0.875               0.8375              \n",
      "6000                0.0755416           1.0                 0.8475              \n",
      "7000                0.0851677           0.9375              0.8395              \n",
      "8000                0.0233209           1.0                 0.8425              \n",
      "9000                0.0251255           1.0                 0.845               \n",
      "10000               0.000143626         1.0                 0.8535              \n",
      "Test accuracy: 0.9080%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print_row(['Step', 'Loss', 'Acc-Train', 'Acc-Valid'])\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % (num_steps // 10) == 0):\n",
    "      test_acc = accuracy(predictions, batch_labels)\n",
    "      valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "      print_row([step, l, test_acc, valid_acc])   \n",
    "  print('Test accuracy: %.4f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
